{"cells":[{"cell_type":"markdown","metadata":{},"source":["\n","<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg\" style=\"vertical-align: top; padding-top: 2px\" width=\"08%\"/></center><p></p><h1><font color=\"#306998\"></font><center>Value-at-Risk</center></h1>\n","<center><b>Kannan Singaravelu</b></center>\n","<center><font size=\"3\">March, 2022</font></center><hr/>\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h1 id=\"Value-at-Risk\">Value-at-Risk<a class=\"anchor-link\" href=\"#Value-at-Risk\">¶</a></h1><p>Value at Risk - <strong>VaR</strong> - is one of the most important metrics that is used to measures the risk associated with a financial position or a portfolio of financial instruments. VaR can be defined as the maximum loss with a confidence level over a predetermined period. Let's say that the 1-day 95% VaR of a portfolio is $\\$100$. This means that 95% of the time, it is expected that - under normal market conditions - we will not lose more than $100 by holding our portfolio over one day.</p>\n","<p>Three approaches that are commonly used in the industry are</p>\n","<ul>\n","<li><strong>Parametric</strong></li>\n","<li><strong>Historical</strong> </li>\n","<li><strong>Monte Carlo</strong></li>\n","</ul>\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h2 id=\"Import-Libraries\">Import Libraries<a class=\"anchor-link\" href=\"#Import-Libraries\">¶</a></h2>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Data manipulation\n","import pandas as pd\n","import numpy as np\n","from numpy.linalg import multi_dot\n","\n","from scipy.stats import norm\n","from tabulate import tabulate\n","\n","# Import matplotlib for visualization\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","# Plot settings\n","plt.style.use('dark_background')\n","matplotlib.rcParams['figure.figsize'] = [24.0, 8.0]\n","matplotlib.rcParams['font.size'] = 10\n","matplotlib.rcParams['lines.linewidth'] = 2.0\n","matplotlib.rcParams['grid.color'] = 'black'\n","\n","from helper import plot_var\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h2 id=\"Retrieve-Data\">Retrieve Data<a class=\"anchor-link\" href=\"#Retrieve-Data\">¶</a></h2><p>We will use the FAANG stocks as before to build for calculation of VaR</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Load locally stored data\n","df = pd.read_csv('data/nasdaqstocks.csv', index_col=0, parse_dates=True)\n","\n","# Check values \n","df\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h2 id=\"Calculate-Returns\">Calculate Returns<a class=\"anchor-link\" href=\"#Calculate-Returns\">¶</a></h2>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Calculate daily returns\n","returns = df.pct_change().dropna()\n","returns.head()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Visualize daily returns\n","fig, ax = plt.subplots(1,len(df.columns), sharey=True)\n","label, color = df.columns, ['green', 'red', 'cornflowerblue', 'orange', 'white']\n","\n","for i in range(len(df.columns)):\n","    ax[i].plot(returns.iloc[:,i], label=label[i], color=color[i])\n","    ax[i].axhline(y=0, color='k', linestyle='--')\n","    ax[i].legend(loc=4)\n","\n","fig.suptitle('Daily Returns');\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h2 id=\"Parametric-VaR\">Parametric VaR<a class=\"anchor-link\" href=\"#Parametric-VaR\">¶</a></h2><p>The Variance-covariance is a parametric method which assumes (almost always) that the returns are normally distributed. In this method, we first calculate the mean and standard deviation of the returns to derive the risk metric. Based on the assumption of normality, we can generalise,\n","<br/><br/>\n","$ VaR = position * (\\mu - z * \\sigma) $</p>\n","<table>\n","<thead><tr>\n","<th style=\"text-align:left\">Confidence Level</th>\n","<th style=\"text-align:left\">Value At Risk     </th>\n","</tr>\n","</thead>\n","<tbody>\n","<tr>\n","<td style=\"text-align:left\"><code>90%</code></td>\n","<td style=\"text-align:left\">$\\mu$ - $1.29$ * $\\sigma$ </td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\"><code>95%</code></td>\n","<td style=\"text-align:left\">$\\mu$ - $1.64$ * $\\sigma$             </td>\n","</tr>\n","<tr>\n","<td style=\"text-align:left\"><code>99%</code></td>\n","<td style=\"text-align:left\">$\\mu$ - $2.33$ * $\\sigma$             </td>\n","</tr>\n","</tbody>\n","</table>\n","<p>where, $\\mu$ is the return, $\\sigma$ is the volatility and $z$ is the number of standard deviation from the mean.</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Visualize VaR at 95% confidence level\n","plot_var()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Calculate mean and standard deviation \n","mean = np.mean(returns['AMD'])\n","stdev = np.std(returns['AMD'])\n","\n","# Calculate VaR at difference confidence level\n","VaR_90 = norm.ppf(1-0.90,mean,stdev)\n","VaR_95 = norm.ppf(1-0.95,mean,stdev) \n","VaR_99 = norm.ppf(1-0.99,mean,stdev)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# number of stdev from the mean\n","norm.ppf(0.05)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Ouput results in tabular format\n","table = [['90%', VaR_90],['95%', VaR_95],['99%', VaR_99] ]\n","header = ['Confidence Level', 'Value At Risk']\n","print(tabulate(table,headers=header))\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<p>Lets now define a VaR function so that we can use it calculate it for individual stocks</p>\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<p><strong>UDF : User Defined Function</strong></p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# VaR function\n","def VaR(dataframe):\n","    var = pd.DataFrame()\n","\n","    for i in [90, 95, 99]:\n","        for j in range(len(df.columns)):\n","            var.loc[i, j] = 100 * norm.ppf(1-i/100, dataframe.iloc[:,j].mean(), dataframe.iloc[:,j].std())\n","\n","    var.columns = df.columns\n","    return var\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# VaR for stocks\n","VaR(returns)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<p>Now, let's assume that we have 1,000 shares of AMD's stock on Dec 30, 2021. What is the maximum loss next day with a confidence level of 99%?</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","num_of_shares = 1000\n","price = df['AMD'].iloc[-1]\n","position = num_of_shares * price \n","\n","amd_var = position * VaR_99\n","\n","print(f'AMD Holding Value: {position}')\n","print(f'AMD VaR at 99% confidence level is: {amd_var}')\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<p>VaR can also be calculated using the above formula at 99% confidence level.</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# VaR calculation by appling direct formulae\n","position * (mean + norm.ppf(1-0.99) * stdev)         # mean-2.33*stdev\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h2 id=\"Historical-VaR\">Historical VaR<a class=\"anchor-link\" href=\"#Historical-VaR\">¶</a></h2><p>Asset returns do not necessarily follow a normal distribution. An alternative is to use sorted returns to evaluate a VaR. This method uses historical data where returns are sorted in ascending order to calculate maximum possible loss for a given confidence level.</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Use quantile function for Historical VaR\n","hVaR_90 = returns['AMD'].quantile(0.10)\n","hVaR_95 = returns['AMD'].quantile(0.05)\n","hVaR_99 = returns['AMD'].quantile(0.01)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","htable = [['90%', hVaR_90],['95%', hVaR_95],['99%', hVaR_99]]\n","print(tabulate(htable,headers=header))\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h2 id=\"MonteCarlo-VaR\">MonteCarlo VaR<a class=\"anchor-link\" href=\"#MonteCarlo-VaR\">¶</a></h2><p>The Monte Carlo simulation approach has a number of similarities to historical simulation. It allows us to use actual historical distributions rather than having to assume normal returns. As returns are assumed to follow a normal distribution, we could generate <em><code>n</code></em> simulated returns with the same mean and standard deviation (derived from the daily returns) and then sorted in ascending order to calculate maximum possible loss for a given confidence level.</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Set seed for reproducibility\n","np.random.seed(42)\n","\n","# Number of simulations\n","n_sims = 5000\n","\n","# Simulate returns and sort\n","sim_returns = np.random.normal(mean, stdev, n_sims)\n","\n","# Use percentile function for MCVaR\n","MCVaR_90 = np.percentile(sim_returns,10)\n","MCVaR_95 = np.percentile(sim_returns, 5)\n","MCVaR_99 = np.percentile(sim_returns,1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","mctable = [['90%', MCVaR_90],['95%', MCVaR_95],['99%', MCVaR_99]]\n","print(tabulate(mctable,headers=header))\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h2 id=\"Scaling-VaR\">Scaling VaR<a class=\"anchor-link\" href=\"#Scaling-VaR\">¶</a></h2><p>Now, let's calculate VaR over a 5-day period. To scale it, multiply by square root of time.\n","<br/><br/>\n","$$ VaR = position * (\\mu - z * \\sigma) * \\sqrt{T}$$</p>\n","<p>where, $T$ is the horizon or forecast period.</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","forecast_days = 5\n","f_VaR_90 = VaR_90*np.sqrt(forecast_days)\n","f_VaR_95 = VaR_95*np.sqrt(forecast_days)\n","f_VaR_99 = VaR_99*np.sqrt(forecast_days)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","ftable = [['90%', f_VaR_90],['95%', f_VaR_95],['99%', f_VaR_99] ]\n","fheader = ['Confidence Level', '5-Day Forecast Value At Risk']\n","print(tabulate(ftable,headers=fheader))\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<p>Let's now calculate AMD VaR over a 5-day period with a confidence level of 99%</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","amd_var_5days = position * f_VaR_99\n","\n","print(f'AMD Holding Value: {position}')\n","print(f'AMD VaR at 99% confidence level is: {amd_var_5days}')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Scaled VaR over different time horizon\n","# plt.figure()\n","plt.plot(range(100),[-100*VaR_95*np.sqrt(x) for x in range(100)], color='orange')\n","plt.xlabel('Horizon')\n","plt.ylabel('Var 95 (%)')\n","plt.title('VaR_95 Scaled by Time');\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h2 id=\"Expected-Short-Fall\">Expected Short Fall<a class=\"anchor-link\" href=\"#Expected-Short-Fall\">¶</a></h2><p>VaR is a reasonable measure of risk if assumption of normality holds. Else, we might underestimate the risk if we observe a fat tail or overestimate the risk if tail is thinner. Expected shortfall or Conditional Value at Risk - <strong>CVaR</strong> - is an estimate of expected shortfall sustained in the worst 1 - x% of scenarios. It is defined as the average loss based on the returns that are lower than the VaR threshold. Assume that we have <em><code>n</code></em> return observations, then the expected shortfall is\n","<br/><br/>\n","$$ CVaR = \\frac 1 n * \\sum_{i=1}^{n} R_i[R \\leq hVaR_{cl}]$$</p>\n","<p>where, $R$ is returns, $hVaR$ is historical VaR and $cl$ is the confidence level.</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Calculate CVar\n","CVaR_90 = returns['AMD'][returns['AMD']<=hVaR_90].mean()\n","CVaR_95 = returns['AMD'][returns['AMD']<=hVaR_95].mean()\n","CVaR_99 = returns['AMD'][returns['AMD']<=hVaR_99].mean()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","ctable = [['90%', CVaR_90],['95%', CVaR_95],['99%', CVaR_99] ]\n","cheader = ['Confidence Level', 'Conditional Value At Risk']\n","print(tabulate(ctable,headers=cheader))\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h2 id=\"Portfolio-VaR\">Portfolio VaR<a class=\"anchor-link\" href=\"#Portfolio-VaR\">¶</a></h2><p>If we know the returns and volatilities of all the assets in the portfolio, we can calculate the VaR for the whole portfolio. We will now derive VaR of an equal weighted portfolio of FAANG stocks.</p>\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h3 id=\"Assign-Weights\">Assign Weights<a class=\"anchor-link\" href=\"#Assign-Weights\">¶</a></h3>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Weights from Minimum Variance Portfolio\n","weights = pd.DataFrame([0., 57.71, 13.14, 29.16, 0.0]).T\n","weights.columns = df.columns\n","weights\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h3 id=\"Portfolio-return\">Portfolio return<a class=\"anchor-link\" href=\"#Portfolio-return\">¶</a></h3>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Portfolio returns\n","port_ret = np.dot(returns, weights.T)\n","port_mean = port_ret.mean()\n","port_mean\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h3 id=\"Portfolio-Volatility\">Portfolio Volatility<a class=\"anchor-link\" href=\"#Portfolio-Volatility\">¶</a></h3>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Portfolio volatility\n","port_stdev = np.sqrt(multi_dot([weights, returns.cov(), weights.T]))\n","port_stdev.flatten()[0]\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h3 id=\"Portfolio-VaR\">Portfolio VaR<a class=\"anchor-link\" href=\"#Portfolio-VaR\">¶</a></h3>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Calculate Portfolio VaR at difference confidence level\n","pVaR_90 = norm.ppf(1-0.90,port_mean,port_stdev).flatten()[0]\n","pVaR_95 = norm.ppf(1-0.95,port_mean,port_stdev).flatten()[0]\n","pVaR_99 = norm.ppf(1-0.99,port_mean,port_stdev).flatten()[0]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Ouput results in tabular format\n","ptable = [['90%', pVaR_90],['95%', pVaR_95],['99%', pVaR_99]]\n","header = ['Confidence Level', 'Value At Risk']\n","print(tabulate(ptable,headers=header))\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<p>Let's now compare the portfolio VaR numbers with that of the individual stocks</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Iterate over symbols\n","portpos=0.\n","for stock in df.columns:\n","    pos = df[stock].iloc[-1] * 1000*weights[stock][0]\n","    pvar = VaR(returns)[stock].iloc[1]\n","\n","    print(f'{stock} Holding Value: {pos:0.8}') \n","    print(f'{stock} VaR at 95% confidence level: {pvar:0.8}%')\n","    print()\n","\n","    portpos += pos\n","\n","print(f'Portfolio Holding Value: {portpos:0.8}')\n","print(f'Portoflio VaR at 95% confidence level: {pVaR_95:0.3}%')\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<p>The VaR for the current portfolio of $\\$ 1.8$ million is 2.41%, which is much lesser than the individual VaR numbers. This signifies the effect of diversification by selecting different stocks.</p>\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<h1 id=\"References\">References<a class=\"anchor-link\" href=\"#References\">¶</a></h1><ul>\n","<li><p><a href=\"https://urldefense.com/v3/__https://docs.scipy.org/doc/scipy/reference/__;!!KGvANbslH1YjwA!pp8ABRV5pvlNNVDnmbQpGv8z5Wc4lDFJ3s74EFrfiGXolaNAXRMhuhP5AupxkJs7xpOLJTeFiw$\">Scipy</a></p>\n","</li>\n","<li><p><a href=\"https://urldefense.com/v3/__https://github.com/astanin/python-tabulate__;!!KGvANbslH1YjwA!pp8ABRV5pvlNNVDnmbQpGv8z5Wc4lDFJ3s74EFrfiGXolaNAXRMhuhP5AupxkJs7xpPIoOvwlA$\">Tabulate</a></p>\n","</li>\n","<li><p>Paul Wilmott (2007), Paul Wilmott introduces Quantitative Finance</p>\n","</li>\n","</ul>\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<hr/>\n","<p><a href=\"https://urldefense.com/v3/__http://twitter.com/kannansi__;!!KGvANbslH1YjwA!pp8ABRV5pvlNNVDnmbQpGv8z5Wc4lDFJ3s74EFrfiGXolaNAXRMhuhP5AupxkJs7xpOvShO3hg$\">Kannan Singaravelu</a> | <a href=\"https://urldefense.com/v3/__https://github.com/kannansingaravelu__;!!KGvANbslH1YjwA!pp8ABRV5pvlNNVDnmbQpGv8z5Wc4lDFJ3s74EFrfiGXolaNAXRMhuhP5AupxkJs7xpPquleyhw$\">GitHub</a></p>\n","<p><font size=\"3\">March, 2022</font></p>\n"]}],"metadata":{"interpreter":{"hash":"b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"},"kernelspec":{"display_name":"Python 3.8.12 ('base')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.12"}},"nbformat":4,"nbformat_minor":1}
